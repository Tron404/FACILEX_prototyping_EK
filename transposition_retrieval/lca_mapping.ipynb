{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ijson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(path, country):\n",
    "    corpus = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "            parser = ijson.parse(f)\n",
    "            aux = {\"country\": \"\", \"label\": \"\", \"text\": \"\"}\n",
    "            for prefix, event, value in parser:\n",
    "                prefix = \".\".join(prefix.split(\".\")[1:])\n",
    "                if (prefix, event) == (\"label\", \"string\"):\n",
    "                    aux[\"label\"] = value\n",
    "                elif (prefix, event) == (\"text\", \"string\"):\n",
    "                    aux[\"text\"] = value\n",
    "                elif (prefix, event) == (\"country\", \"string\"):\n",
    "                    aux[\"country\"] = value\n",
    "\n",
    "                if aux[\"country\"] == country and aux[\"text\"] != \"\" and aux[\"label\"] != \"\":\n",
    "                    corpus.append(aux)\n",
    "                    aux = {\"country\": \"\", \"label\": \"\", \"text\": \"\"}\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/ML-dataset/train-queries.json\"\n",
    "data_it = pd.DataFrame(read_data(path, \"ITA\"))\n",
    "data_fr = pd.DataFrame(read_data(path, \"FRA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_it[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keddie/anaconda3/envs/facilex_caselaw/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"../models/paraphrase-multilingual-mpnet-base-v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started encoding\n",
      "Started encoding\n"
     ]
    }
   ],
   "source": [
    "print(\"Started encoding\")\n",
    "data_it[\"encoded_it\"] = data_it[\"text\"].apply(model.encode)\n",
    "print(\"Started encoding\")\n",
    "data_fr[\"encoded_fr\"] = data_fr[\"text\"].apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_it = np.asarray(data_it[\"label\"].tolist())\n",
    "lab_fr = np.asarray(data_fr[\"label\"].tolist())\n",
    "\n",
    "aggregated_data = []\n",
    "\n",
    "for lab in lab_it:\n",
    "    min_label = np.min([data_it[data_it[\"label\"] == lab].shape[0],  data_fr[data_fr[\"label\"] == lab].shape[0]])\n",
    "\n",
    "    if min_label == 0:\n",
    "        continue\n",
    "    else:\n",
    "        aggregated_data.append([data_it[data_it[\"label\"] == lab].iloc[:min_label], data_fr[data_fr[\"label\"] == lab].iloc[:min_label]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10307/10307 [00:17<00:00, 586.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "aligned_texts_dir = []\n",
    "limits = (0,1000000)\n",
    "for dir in tqdm(aggregated_data[limits[0]:limits[1]]):\n",
    "    array_it = np.asarray(dir[0][\"encoded_it\"].tolist())\n",
    "    array_fr = np.asarray(dir[1][\"encoded_fr\"].tolist())\n",
    "\n",
    "    scores = cosine_similarity(array_it, array_fr)\n",
    "    aligned_texts = []\n",
    "    for idx, score in enumerate(scores):\n",
    "        top_k = np.argsort(score)[::-1][0]\n",
    "        aligned_texts.append([idx, top_k])\n",
    "    aligned_texts_dir.append(aligned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(aligned) for aligned in aligned_texts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10307it [01:13, 140.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_it</th>\n",
       "      <th>encoded_it</th>\n",
       "      <th>text_fr</th>\n",
       "      <th>encoded_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32016L2341</td>\n",
       "      <td>1. Gli articoli 52 e 53 non ostano ad alcuna d...</td>\n",
       "      <td>[-0.01917797, 0.01133264, -0.008022693, 0.0453...</td>\n",
       "      <td>1. Les articles 52 et 53 ne font obstacle à au...</td>\n",
       "      <td>[-0.044572506, 0.050717562, -0.009113831, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>32016L2341</td>\n",
       "      <td>Gli Stati membri garantiscono che gli EPAP sia...</td>\n",
       "      <td>[-0.15083398, -0.057951342, -0.009174005, -0.0...</td>\n",
       "      <td>Les États membres veillent à ce que les IRP so...</td>\n",
       "      <td>[-0.13886526, -0.07500404, -0.009932162, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>32016L2341</td>\n",
       "      <td>Gli Stati membri assicurano che vi sia una sep...</td>\n",
       "      <td>[-0.114227384, 0.0053351, -0.009329527, 0.0703...</td>\n",
       "      <td>Les États membres veillent à ce qu'il existe u...</td>\n",
       "      <td>[-0.09838905, 0.017340802, -0.009662485, 0.107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>32016L2341</td>\n",
       "      <td>1. Entro 13 gennaio 2023, la Commissione esegu...</td>\n",
       "      <td>[-0.038859554, -0.17914939, -0.012377142, -0.0...</td>\n",
       "      <td>1. Au plus tard le 13 janvier 2023, la Commiss...</td>\n",
       "      <td>[-0.041650075, -0.18207741, -0.011810097, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>32016L2341</td>\n",
       "      <td>1. Gli Stati membri consentono agli EPAP regis...</td>\n",
       "      <td>[-0.07931274, -0.01991996, -0.009524323, 0.021...</td>\n",
       "      <td>1. Les États membres autorisent les IRP enregi...</td>\n",
       "      <td>[-0.06276633, -0.06766292, -0.008952431, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>32016L1629</td>\n",
       "      <td>1. Le unità navali munite di un certificato de...</td>\n",
       "      <td>[-0.0065439087, 0.043382887, -0.00880788, -0.1...</td>\n",
       "      <td>1. Les bâtiments munis d'un certificat valide ...</td>\n",
       "      <td>[-0.081004485, 0.1373705, -0.009739099, -0.123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>32016L1629</td>\n",
       "      <td>Ai fini della presente direttiva s'intende per...</td>\n",
       "      <td>[0.037924215, -0.15280026, -0.016648697, -0.12...</td>\n",
       "      <td>Aux fins de la présente directive, on entend p...</td>\n",
       "      <td>[0.054068886, -0.18845516, -0.018823588, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>32016L1629</td>\n",
       "      <td>La presente direttiva stabilisce:\\na)\\ni requi...</td>\n",
       "      <td>[-0.0077311955, -0.10552563, -0.011854096, -0....</td>\n",
       "      <td>La présente directive établit:\\na)\\nles prescr...</td>\n",
       "      <td>[-0.0702611, -0.11325889, -0.013084402, -0.095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>32016L1629</td>\n",
       "      <td>1. La presente direttiva si applica alle segue...</td>\n",
       "      <td>[0.0022214877, -0.22605956, -0.012241536, -0.0...</td>\n",
       "      <td>1. La présente directive s'applique aux bâtime...</td>\n",
       "      <td>[-0.09247355, -0.1562672, -0.012801878, -0.072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>32016L1629</td>\n",
       "      <td>1. Le autorità competenti degli Stati membri p...</td>\n",
       "      <td>[-0.012884406, 0.015223969, -0.009372182, -0.1...</td>\n",
       "      <td>1. Les autorités compétentes des États membres...</td>\n",
       "      <td>[-0.08145498, 0.09418182, -0.009445429, -0.096...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                            text_it  \\\n",
       "0      32016L2341  1. Gli articoli 52 e 53 non ostano ad alcuna d...   \n",
       "56     32016L2341  Gli Stati membri garantiscono che gli EPAP sia...   \n",
       "101    32016L2341  Gli Stati membri assicurano che vi sia una sep...   \n",
       "520    32016L2341  1. Entro 13 gennaio 2023, la Commissione esegu...   \n",
       "553    32016L2341  1. Gli Stati membri consentono agli EPAP regis...   \n",
       "...           ...                                                ...   \n",
       "9449   32016L1629  1. Le unità navali munite di un certificato de...   \n",
       "9597   32016L1629  Ai fini della presente direttiva s'intende per...   \n",
       "9745   32016L1629  La presente direttiva stabilisce:\\na)\\ni requi...   \n",
       "10017  32016L1629  1. La presente direttiva si applica alle segue...   \n",
       "10361  32016L1629  1. Le autorità competenti degli Stati membri p...   \n",
       "\n",
       "                                              encoded_it  \\\n",
       "0      [-0.01917797, 0.01133264, -0.008022693, 0.0453...   \n",
       "56     [-0.15083398, -0.057951342, -0.009174005, -0.0...   \n",
       "101    [-0.114227384, 0.0053351, -0.009329527, 0.0703...   \n",
       "520    [-0.038859554, -0.17914939, -0.012377142, -0.0...   \n",
       "553    [-0.07931274, -0.01991996, -0.009524323, 0.021...   \n",
       "...                                                  ...   \n",
       "9449   [-0.0065439087, 0.043382887, -0.00880788, -0.1...   \n",
       "9597   [0.037924215, -0.15280026, -0.016648697, -0.12...   \n",
       "9745   [-0.0077311955, -0.10552563, -0.011854096, -0....   \n",
       "10017  [0.0022214877, -0.22605956, -0.012241536, -0.0...   \n",
       "10361  [-0.012884406, 0.015223969, -0.009372182, -0.1...   \n",
       "\n",
       "                                                 text_fr  \\\n",
       "0      1. Les articles 52 et 53 ne font obstacle à au...   \n",
       "56     Les États membres veillent à ce que les IRP so...   \n",
       "101    Les États membres veillent à ce qu'il existe u...   \n",
       "520    1. Au plus tard le 13 janvier 2023, la Commiss...   \n",
       "553    1. Les États membres autorisent les IRP enregi...   \n",
       "...                                                  ...   \n",
       "9449   1. Les bâtiments munis d'un certificat valide ...   \n",
       "9597   Aux fins de la présente directive, on entend p...   \n",
       "9745   La présente directive établit:\\na)\\nles prescr...   \n",
       "10017  1. La présente directive s'applique aux bâtime...   \n",
       "10361  1. Les autorités compétentes des États membres...   \n",
       "\n",
       "                                              encoded_fr  \n",
       "0      [-0.044572506, 0.050717562, -0.009113831, 0.02...  \n",
       "56     [-0.13886526, -0.07500404, -0.009932162, -0.02...  \n",
       "101    [-0.09838905, 0.017340802, -0.009662485, 0.107...  \n",
       "520    [-0.041650075, -0.18207741, -0.011810097, -0.0...  \n",
       "553    [-0.06276633, -0.06766292, -0.008952431, 0.028...  \n",
       "...                                                  ...  \n",
       "9449   [-0.081004485, 0.1373705, -0.009739099, -0.123...  \n",
       "9597   [0.054068886, -0.18845516, -0.018823588, -0.13...  \n",
       "9745   [-0.0702611, -0.11325889, -0.013084402, -0.095...  \n",
       "10017  [-0.09247355, -0.1562672, -0.012801878, -0.072...  \n",
       "10361  [-0.08145498, 0.09418182, -0.009445429, -0.096...  \n",
       "\n",
       "[613788 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for dir, aligned in tqdm(zip(aggregated_data[limits[0]:limits[1]], aligned_texts_dir)):\n",
    "    br_it = dir[0].iloc[np.asarray(aligned)[:,0]].drop(\"country\", axis = 1)\n",
    "    br_fr = dir[1].iloc[np.asarray(aligned)[:,1]].drop(\"country\", axis = 1)\n",
    "\n",
    "    br_it.columns = [\"label\", \"text_it\", \"encoded_it\"]\n",
    "    br_fr.columns = [\"label\", \"text_fr\", \"encoded_fr\"]\n",
    "\n",
    "    aux_df = br_it.copy(deep = True)\n",
    "    aux_df[\"text_fr\"] = br_fr[\"text_fr\"].tolist()\n",
    "    aux_df[\"encoded_fr\"] = br_fr[\"encoded_fr\"].tolist()\n",
    "\n",
    "    df = pd.concat([df, aux_df])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 376735708944 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     linear_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: torch\u001b[38;5;241m.\u001b[39mmatmul(lca\u001b[38;5;241m.\u001b[39mT, x)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linear_mapping\n\u001b[0;32m----> 6\u001b[0m mapp \u001b[38;5;241m=\u001b[39m \u001b[43mlca_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoded_it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoded_fr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mlca_mapping\u001b[0;34m(train_sl, train_tl)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlca_mapping\u001b[39m(train_sl, train_tl):\n\u001b[0;32m----> 2\u001b[0m     lca \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_sl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m     linear_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: torch\u001b[38;5;241m.\u001b[39mmatmul(lca\u001b[38;5;241m.\u001b[39mT, x)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linear_mapping\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 376735708944 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "def lca_mapping(train_sl, train_tl):\n",
    "    lca = torch.matmul(torch.linalg.pinv(train_tl.T),train_sl.T).to(device)\n",
    "    linear_mapping = lambda x: torch.matmul(lca.T, x).to(device)\n",
    "    return linear_mapping\n",
    "\n",
    "mapp = lca_mapping(torch.as_tensor(np.asarray(df[\"encoded_it\"].iloc[:int(0.5*len(df))].tolist())), torch.as_tensor(np.asarray(df[\"encoded_fr\"].iloc[:int(0.5*len(df))].tolist())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facilex_caselaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
