{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# assumption that data contains html elements\n",
    "def sanitize_data(text: str) -> str:\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"&nbsp;\", \"\", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# given the embedded representation of a query case and the embeddings of the cases through which to search, alongside their respective CELEX IDs,\n",
    "# return the ordered indices (from most similar to least) of retrieved cases\n",
    "def cosine_similarity_search(query: np.ndarray, search_space: np.ndarray, query_celex: str, search_space_celex: list, top_k: int = 5) -> list:\n",
    "    cosine_scores: list = cosine_similarity(query.reshape(1,-1), search_space)[0]\n",
    "\n",
    "    all_matches: np.ndarray = np.argsort(cosine_scores)[::-1]\n",
    "    best_matches: np.ndarray = all_matches[:top_k]\n",
    "    search_space_celex: list = search_space_celex[best_matches]\n",
    "\n",
    "    similar_cases: list = []\n",
    "    for retrieved_case, retrieved_case_celex in zip(best_matches, search_space_celex):\n",
    "        if query_celex == retrieved_case_celex:\n",
    "            similar_cases.append(retrieved_case)\n",
    "\n",
    "    return similar_cases\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # for embedding using transformers\n",
    "    embedding_model: SentenceTransformer = SentenceTransformer(\"../models/multi-qa-mpnet-base-dot-v1\").to(device)\n",
    "\n",
    "    data: dict = json.load(open(\"example_input.json\", \"r\"))\n",
    "    data[\"query\"][\"summaryEn\"] = sanitize_data(data[\"query\"][\"summaryEn\"])\n",
    "    for search_text in data[\"search_space\"]:\n",
    "        search_text[\"summaryEn\"] = sanitize_data(search_text[\"summaryEn\"])\n",
    "\n",
    "    search_celex = []\n",
    "    search_embedded = []\n",
    "    search_text = []\n",
    "    search_jurisdiction = []\n",
    "    for search_space_item in data[\"search_space\"]:\n",
    "        search_embedded.append(embedding_model.encode(search_space_item[\"summaryEn\"]))\n",
    "        search_celex.append(search_space_item[\"celex\"])\n",
    "        search_text.append(search_space_item[\"summaryEn\"])\n",
    "        search_jurisdiction.append(search_space_item[\"jurisdiction\"])\n",
    "\n",
    "    query_embedded: np.ndarray = embedding_model.encode(data[\"query\"][\"summaryEn\"])\n",
    "    search_celex = np.asarray(search_celex)\n",
    "    search_embedded = np.asarray(search_embedded)\n",
    "    search_text = np.asarray(search_text)\n",
    "    search_jurisdiction = np.asarray(search_jurisdiction)\n",
    "\n",
    "    recommended_idx: list = cosine_similarity_search(query_embedded, search_embedded, data[\"query\"][\"celex\"], search_celex)\n",
    "    output_data = [{\"summaryEn\": search_text[idx], \"celex\": search_celex[idx], \"jurisdiction\": search_jurisdiction[idx]} for idx in recommended_idx]\n",
    "\n",
    "    json.dump(output_data, open(\"example_output.json\", \"w\"))\n",
    "\n",
    "    del embedding_model    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facilex_caselaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
