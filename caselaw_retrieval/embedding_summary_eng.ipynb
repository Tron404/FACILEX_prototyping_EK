{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>court</th>\n",
       "      <th>courtEng</th>\n",
       "      <th>dateOfDocument</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>summaryEn</th>\n",
       "      <th>language</th>\n",
       "      <th>decisionType</th>\n",
       "      <th>...</th>\n",
       "      <th>eurovoc</th>\n",
       "      <th>facilexOntology</th>\n",
       "      <th>nationalIdentifier</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>text</th>\n",
       "      <th>classifiers</th>\n",
       "      <th>celex</th>\n",
       "      <th>citation_all</th>\n",
       "      <th>citation_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VSRH, Kž eun 27/2017-4</td>\n",
       "      <td>Vrhovni sud Republike Hrvatske</td>\n",
       "      <td>The Supreme Court of the Republic of Croatia</td>\n",
       "      <td>2017-11-07T23:00:00Z</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>[content and form of European Arrest Warrant, ...</td>\n",
       "      <td>&lt;p class=\"ql-align-justify\"&gt;Predmet se odnosi ...</td>\n",
       "      <td>The case concerns the crime of fraud committed...</td>\n",
       "      <td>{'label': 'Croatian', 'code': 'HR'}</td>\n",
       "      <td>{'label': 'Other', 'code': 'Ruling'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Kž eun 27/2017-4</td>\n",
       "      <td></td>\n",
       "      <td>https://sudskapraksa.csp.vsrh.hr/decisionPdf?i...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Content of EAW]</td>\n",
       "      <td>{32002F0584}</td>\n",
       "      <td>{32002F0584.Article_8.Paragraph_1.Point_c}</td>\n",
       "      <td>{32002F0584.Article_8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rechtbank Amsterdam, 11-06-2020, ECLI:NL:RBAMS...</td>\n",
       "      <td>Rechtbank Amsterdam</td>\n",
       "      <td>Court of Amsterdam</td>\n",
       "      <td>2020-11-10T23:00:00Z</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>[FW Decision 2002/584 (EAW), assault]</td>\n",
       "      <td>None</td>\n",
       "      <td>The case concerns the crime of [assault.] prov...</td>\n",
       "      <td>{'label': 'Dutch', 'code': 'NL'}</td>\n",
       "      <td>{'label': 'Judgment', 'code': 'J'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>13/751267-20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Non-mandatory ground for refusal (double crim...</td>\n",
       "      <td>{32002F0584}</td>\n",
       "      <td>{32002F0584.Article_3.Paragraph_3, 32002F0584....</td>\n",
       "      <td>{32002F0584.Article_3, 32002F0584.Article_2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wyrok Sądu Najwyższego z dnia 4 lipca 2013 r. ...</td>\n",
       "      <td>Sąd Najwyższy</td>\n",
       "      <td>Supreme Court</td>\n",
       "      <td>2013-07-03T22:00:00Z</td>\n",
       "      <td>Poland</td>\n",
       "      <td>[detention on remand, FW Decision 2002/584 (EAW)]</td>\n",
       "      <td>&lt;p&gt;Stosowanie tymczasowego aresztowania w toku...</td>\n",
       "      <td>The application of detention on remand in the ...</td>\n",
       "      <td>{'label': 'Polish', 'code': 'PL'}</td>\n",
       "      <td>{'label': 'Judgment', 'code': 'J'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>III KK 21/13</td>\n",
       "      <td>Supreme Court Database</td>\n",
       "      <td>http://www.sn.pl/orzecznictwo/SitePages/baza_o...</td>\n",
       "      <td></td>\n",
       "      <td>[Detention conditions]</td>\n",
       "      <td>{32002F0584}</td>\n",
       "      <td>{32002F0584.Article_27}</td>\n",
       "      <td>{32002F0584.Article_27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rechtbank Amsterdam, 14-09-2023, ECLI:NL:RBAMS...</td>\n",
       "      <td>Rechtbank Amsterdam</td>\n",
       "      <td>Court of Amsterdam</td>\n",
       "      <td>2023-09-13T22:00:00Z</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>[Regulation 2018/1805, crime unknown]</td>\n",
       "      <td></td>\n",
       "      <td>The case concerns the crime of [unknown] provi...</td>\n",
       "      <td>{'label': 'Dutch', 'code': 'NL'}</td>\n",
       "      <td>{'label': 'Judgment', 'code': 'J'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>23/014471</td>\n",
       "      <td>rechtspraak.nl</td>\n",
       "      <td>https://uitspraken.rechtspraak.nl/#!/details?i...</td>\n",
       "      <td></td>\n",
       "      <td>[Freezing, Transmission of a freezing/confisca...</td>\n",
       "      <td>{32018R1805}</td>\n",
       "      <td>{32018R1805.Article_4.Paragraph_1, 32018R1805....</td>\n",
       "      <td>{32018R1805.Article_4, 32018R1805.Article_8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juzgado Central de Instrucción núm. 4. Auto 88...</td>\n",
       "      <td>Juzgado Central de Instrucción núm. 4</td>\n",
       "      <td>Central Examining Court n. 4</td>\n",
       "      <td>2023-07-06T22:00:00Z</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[FW Decision 2002/584 (EAW), principle of mutu...</td>\n",
       "      <td>&lt;p&gt;El caso se refiere a los delitos de El caso...</td>\n",
       "      <td>The case concerns the crimes of The case conce...</td>\n",
       "      <td>{'label': 'Spanish', 'code': 'ES'}</td>\n",
       "      <td>{'label': 'Order', 'code': 'O'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>AAN 7411/2023</td>\n",
       "      <td>Centro de Documentación Judicial</td>\n",
       "      <td>https://www.poderjudicial.es/search/AN/openDoc...</td>\n",
       "      <td></td>\n",
       "      <td>[Double criminality, Non-mandatory ground for ...</td>\n",
       "      <td>{32002F0584}</td>\n",
       "      <td>{32002F0584}</td>\n",
       "      <td>{32002F0584}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                             VSRH, Kž eun 27/2017-4   \n",
       "1  Rechtbank Amsterdam, 11-06-2020, ECLI:NL:RBAMS...   \n",
       "2  Wyrok Sądu Najwyższego z dnia 4 lipca 2013 r. ...   \n",
       "3  Rechtbank Amsterdam, 14-09-2023, ECLI:NL:RBAMS...   \n",
       "4  Juzgado Central de Instrucción núm. 4. Auto 88...   \n",
       "\n",
       "                                   court  \\\n",
       "0         Vrhovni sud Republike Hrvatske   \n",
       "1                    Rechtbank Amsterdam   \n",
       "2                         Sąd Najwyższy    \n",
       "3                    Rechtbank Amsterdam   \n",
       "4  Juzgado Central de Instrucción núm. 4   \n",
       "\n",
       "                                       courtEng        dateOfDocument  \\\n",
       "0  The Supreme Court of the Republic of Croatia  2017-11-07T23:00:00Z   \n",
       "1                           Court of Amsterdam   2020-11-10T23:00:00Z   \n",
       "2                                 Supreme Court  2013-07-03T22:00:00Z   \n",
       "3                           Court of Amsterdam   2023-09-13T22:00:00Z   \n",
       "4                  Central Examining Court n. 4  2023-07-06T22:00:00Z   \n",
       "\n",
       "  jurisdiction                                           keywords  \\\n",
       "0      Croatia  [content and form of European Arrest Warrant, ...   \n",
       "1  Netherlands              [FW Decision 2002/584 (EAW), assault]   \n",
       "2       Poland  [detention on remand, FW Decision 2002/584 (EAW)]   \n",
       "3  Netherlands              [Regulation 2018/1805, crime unknown]   \n",
       "4        Spain  [FW Decision 2002/584 (EAW), principle of mutu...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <p class=\"ql-align-justify\">Predmet se odnosi ...   \n",
       "1                                               None   \n",
       "2  <p>Stosowanie tymczasowego aresztowania w toku...   \n",
       "3                                                      \n",
       "4  <p>El caso se refiere a los delitos de El caso...   \n",
       "\n",
       "                                           summaryEn  \\\n",
       "0  The case concerns the crime of fraud committed...   \n",
       "1  The case concerns the crime of [assault.] prov...   \n",
       "2  The application of detention on remand in the ...   \n",
       "3  The case concerns the crime of [unknown] provi...   \n",
       "4  The case concerns the crimes of The case conce...   \n",
       "\n",
       "                              language                          decisionType  \\\n",
       "0  {'label': 'Croatian', 'code': 'HR'}  {'label': 'Other', 'code': 'Ruling'}   \n",
       "1     {'label': 'Dutch', 'code': 'NL'}    {'label': 'Judgment', 'code': 'J'}   \n",
       "2    {'label': 'Polish', 'code': 'PL'}    {'label': 'Judgment', 'code': 'J'}   \n",
       "3     {'label': 'Dutch', 'code': 'NL'}    {'label': 'Judgment', 'code': 'J'}   \n",
       "4   {'label': 'Spanish', 'code': 'ES'}       {'label': 'Order', 'code': 'O'}   \n",
       "\n",
       "   ... eurovoc facilexOntology nationalIdentifier  \\\n",
       "0  ...      []                   Kž eun 27/2017-4   \n",
       "1  ...      []                       13/751267-20   \n",
       "2  ...      []                       III KK 21/13   \n",
       "3  ...      []                          23/014471   \n",
       "4  ...      []                      AAN 7411/2023   \n",
       "\n",
       "                              source  \\\n",
       "0                                      \n",
       "1                                      \n",
       "2             Supreme Court Database   \n",
       "3                     rechtspraak.nl   \n",
       "4  Centro de Documentación Judicial    \n",
       "\n",
       "                                           sourceUrl  text  \\\n",
       "0  https://sudskapraksa.csp.vsrh.hr/decisionPdf?i...  None   \n",
       "1                                                            \n",
       "2  http://www.sn.pl/orzecznictwo/SitePages/baza_o...         \n",
       "3  https://uitspraken.rechtspraak.nl/#!/details?i...         \n",
       "4  https://www.poderjudicial.es/search/AN/openDoc...         \n",
       "\n",
       "                                         classifiers         celex  \\\n",
       "0                                   [Content of EAW]  {32002F0584}   \n",
       "1  [Non-mandatory ground for refusal (double crim...  {32002F0584}   \n",
       "2                             [Detention conditions]  {32002F0584}   \n",
       "3  [Freezing, Transmission of a freezing/confisca...  {32018R1805}   \n",
       "4  [Double criminality, Non-mandatory ground for ...  {32002F0584}   \n",
       "\n",
       "                                        citation_all  \\\n",
       "0         {32002F0584.Article_8.Paragraph_1.Point_c}   \n",
       "1  {32002F0584.Article_3.Paragraph_3, 32002F0584....   \n",
       "2                            {32002F0584.Article_27}   \n",
       "3  {32018R1805.Article_4.Paragraph_1, 32018R1805....   \n",
       "4                                       {32002F0584}   \n",
       "\n",
       "                               citation_article  \n",
       "0                        {32002F0584.Article_8}  \n",
       "1  {32002F0584.Article_3, 32002F0584.Article_2}  \n",
       "2                       {32002F0584.Article_27}  \n",
       "3  {32018R1805.Article_4, 32018R1805.Article_8}  \n",
       "4                                  {32002F0584}  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "path_data = \"../data/caselaw_data/\"\n",
    "\n",
    "main_attributes = json.load(open(path_data + \"2301.json\", \"rb\"))\n",
    "os.mkdir(\"../data/caselaw_emb/\") if \"caselaw_emb\" not in os.listdir(\"../data/\") else 1\n",
    "\n",
    "data = {key: [] for key in main_attributes}\n",
    "\n",
    "for case in os.listdir(path_data):\n",
    "    file = json.load(open(path_data + case, \"rb\"))\n",
    "    for attribute in data.keys():\n",
    "        data[attribute].append(file[attribute])\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "# select only relevant data and drop any data points that have no EU provisions mentioned\n",
    "# relevant_cols = [\"title\", \"summaryEn\", \"euCaselaw\", \"euProvisions\", \"jurisdiction\"]\n",
    "# df = df[relevant_cols]\n",
    "df = df[(df[\"euProvisions\"].str.len() > 0)]\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "def get_citation_to_eu_instrument(item):\n",
    "    complete_citation = [mention[\"label\"] + \"_\" + mention[\"value\"] for mention in item[\"itemsBase\"] if mention[\"value\"] != \"\"]\n",
    "    return item[\"celex\"] + \".\" + \".\".join(complete_citation) if len(complete_citation) > 0 else item[\"celex\"]\n",
    "\n",
    "# denest the jurisdiction, CELEX, and EU citations\n",
    "df[\"jurisdiction\"] = df[\"jurisdiction\"].apply(lambda x: x[\"label\"])\n",
    "df[\"celex\"] = df[\"euProvisions\"].apply(lambda x: set([citation[\"celex\"] for citation in x]))\n",
    "df[\"citation_all\"] = df[\"euProvisions\"].apply(lambda x: set([get_citation_to_eu_instrument(citation) for citation in x]))\n",
    "df[\"citation_article\"] = df[\"euProvisions\"].apply(lambda x: set([f\"{citation['celex']}.{citation['itemsBase'][0]['label']}_{citation['itemsBase'][0]['value']}\" if citation['itemsBase'][0]['value'] != \"\" else citation['celex']  for citation in x]))\n",
    "\n",
    "# drop EU provisions, as all information was extracted from it\n",
    "df = df.drop([\"euProvisions\"], axis = 1)\n",
    "\n",
    "# sanitise summaries\n",
    "df[\"summaryEn\"] = df[\"summaryEn\"].apply(lambda x: re.sub(r\"(?:https://)?www.[^\\s<]+\", \"\", x)) # remove any potential links\n",
    "df[\"summaryEn\"] = df[\"summaryEn\"].apply(lambda x: re.sub(r\"<.*?>\", \"\", x)) # remove html elements\n",
    "df[\"summaryEn\"] = df[\"summaryEn\"].apply(lambda x: re.sub(r\"&nbsp;\", \"\", x)) # remove html elements\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jurisdiction\n",
       "Italy          70\n",
       "Netherlands    62\n",
       "Bulgaria       57\n",
       "Portugal       52\n",
       "Poland         48\n",
       "Germany        13\n",
       "Spain          11\n",
       "Croatia         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jurisdiction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keddie/anaconda3/envs/facilex_caselaw/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"../models/multi-qa-mpnet-base-dot-v1\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r ../data/caselaw_emb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_embeddings(data, tokenized, pad_tok_id):\n",
    "  if \"attention_mask\" in tokenized:\n",
    "    attention_mask = tokenized[\"attention_mask\"]\n",
    "  else: # apparently ErnieM does NOT have attenion IDs in the tokenized output, so I am \"computing\" them myself - like in all other models, the model should not pay attention to [PAD] tokens, so they are ignored/not paid attention to\n",
    "    print(\"Oh no\")\n",
    "    token_ids = tokenized[\"input_ids\"][0]\n",
    "    padding_ids = len([tok for tok in token_ids if tok == pad_tok_id]) # count how many [PAD] tokens there are\n",
    "    attention_mask = torch.ones((tokenized[\"input_ids\"].shape)).to(device)\n",
    "    if padding_ids > 0:\n",
    "        attention_mask[:,-padding_ids:] = 0\n",
    "    attention_mask = torch.tensor(attention_mask).to(device)\n",
    "    \n",
    "  attention_expanded = attention_mask.unsqueeze(-1).expand(data.size()).float()\n",
    "  data_attention = data * attention_expanded\n",
    "  return torch.sum(data_attention, 1) / torch.clamp(attention_expanded.sum(1), min=1e-9) # to not divide by 0\n",
    "\n",
    "def encode_sentence_bert(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\", return_attention_mask=True)\n",
    "    \n",
    "    pad_tok_id = tokenizer(\"[PAD]\")\n",
    "    pad_tok_id = pad_tok_id[\"input_ids\"][1]\n",
    "    \n",
    "    aux = {}\n",
    "    for key in inputs.keys(): # cast tokenized input to GPU\n",
    "      aux[key] = inputs[key].to(device)\n",
    "    inputs = aux\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    outputs = pool_embeddings(outputs[0], inputs, pad_tok_id)\n",
    "\n",
    "    last_hidden_state = outputs.cpu().detach().numpy()  # The last hidden-state is the first element of the output tuple\n",
    "\n",
    "    return last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keddie/anaconda3/envs/facilex_caselaw/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import fasttext\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_sentence_embedding_fasttext(tokens, model):\n",
    "    aux = []\n",
    "    for token in tokens:\n",
    "        aux.append(model.get_word_vector(token))\n",
    "    \n",
    "    aux = np.asarray(aux)\n",
    "\n",
    "    return np.mean(aux, axis = 0)\n",
    "\n",
    "\n",
    "def get_embedding_all_fasttext(data, model):\n",
    "    match model:\n",
    "        case \"facilex\":\n",
    "            if \"fasttext_facilex.bin\" in os.listdir(\"../models/\"):\n",
    "                fasttext_model = fasttext.load_model(f\"../models/fasttext_{model}.bin\")\n",
    "            else:\n",
    "                fasttext_model = train_fasttext()\n",
    "        case _:\n",
    "            fasttext_model = fasttext.load_model(f\"../models/{model}.bin\")\n",
    "            \n",
    "    data[\"summaryEn\"] = data[\"summaryEn\"].apply(summary_preprocessing)\n",
    "    data[\"summaryEn\"] = data[\"summaryEn\"].str.split(\" \")\n",
    "    all_vectors = data[\"summaryEn\"].apply(get_sentence_embedding_fasttext, args = (fasttext_model, ))        \n",
    "\n",
    "    return np.asarray(all_vectors.tolist())\n",
    "\n",
    "def train_fasttext():\n",
    "    with open(\"processed_text_fasttext.txt\", \"w\") as file:\n",
    "        for text in df[\"summaryEn\"].apply(summary_preprocessing):\n",
    "            file.write(text)\n",
    "            file.write(\"\\n\")\n",
    "    fasttext_model = fasttext.train_unsupervised(\"processed_text_fasttext.txt\", dim = 500, epoch = 20)\n",
    "    fasttext_model.save_model(\"../models/fasttext_facilex.bin\")\n",
    "\n",
    "    return fasttext_model\n",
    "\n",
    "def summary_preprocessing(text):\n",
    "    text = re.sub(r\"[^\\w ]+\", \" \", text)\n",
    "    text = re.sub(r\" {2,}\", \" \", text)\n",
    "    text = text.strip(string.punctuation)\n",
    "    text = text.lower()\n",
    "    text = lemmatizer(text)\n",
    "    text = [token.lemma_ for token in text]\n",
    "    text = \" \".join([word for word in text if word not in stop_words])\n",
    "\n",
    "    return text\n",
    "\n",
    "def summary_preprocessing_transformer(text):\n",
    "    text = re.sub(r\"[^\\w ]+\", \" \", text)\n",
    "    text = re.sub(r\" {2,}\", \" \", text)\n",
    "    text = text.strip(string.punctuation)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "all_tfidf = TfidfVectorizer(binary = True, ngram_range = (1,2), tokenizer = word_tokenize, lowercase = True)\n",
    "all_tfidf.fit(np.asarray(df[\"summaryEn\"].apply(summary_preprocessing).tolist()))\n",
    "\n",
    "def get_sentence_embedding_tfidf(data):\n",
    "    data[\"summaryEn\"] = data[\"summaryEn\"].apply(summary_preprocessing)\n",
    "    all_vectors = np.asarray(all_tfidf.transform(np.asarray(data[\"summaryEn\"].tolist())).toarray())\n",
    "\n",
    "    return all_vectors\n",
    "\n",
    "# train_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_228646/3048227423.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"summaryEn\"] = data[\"summaryEn\"].apply(summary_preprocessing)\n",
      "Read 0M words\n",
      "Number of words:  1187\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   17990 lr:  0.000000 avg.loss:  2.364569 ETA:   0h 0m 0s\n",
      "/tmp/ipykernel_228646/3048227423.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"summaryEn\"] = data[\"summaryEn\"].apply(summary_preprocessing)\n",
      "/tmp/ipykernel_228646/3048227423.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"summaryEn\"] = data[\"summaryEn\"].str.split(\" \")\n",
      "100%|██████████| 8/8 [00:49<00:00,  6.19s/it]\n"
     ]
    }
   ],
   "source": [
    "embd_name_map = {\n",
    "    frozenset([get_sentence_embedding_tfidf]): \"tfidf\", \n",
    "    frozenset([get_embedding_all_fasttext, \"facilex\"]): \"fasttext_facilex\"\n",
    "}\n",
    "\n",
    "for jurisdiction in tqdm(df[\"jurisdiction\"].unique()):\n",
    "    for embedding_method in [get_sentence_embedding_tfidf, [get_embedding_all_fasttext, \"facilex\"]]:\n",
    "        aux = df.copy(True)\n",
    "        if not type(embedding_method) == list:\n",
    "            emb_vec = embedding_method(aux[aux[\"jurisdiction\"] == jurisdiction])\n",
    "        else:\n",
    "            emb_vec = embedding_method[0](aux[aux[\"jurisdiction\"] == jurisdiction], embedding_method[1])\n",
    "\n",
    "        os.mkdir(f\"../data/caselaw_emb/{jurisdiction}\") if jurisdiction not in os.listdir(\"../data/caselaw_emb/\") else 1\n",
    "        pickle.dump(emb_vec, open(f\"../data/caselaw_emb/{jurisdiction}/emb_{embd_name_map[frozenset([embedding_method] if type(embedding_method) != list else embedding_method)]}.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:32<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# models = [\"distiluse-base-multilingual-cased-v2\", \"paraphrase-multilingual-mpnet-base-v2\", \"bert-base-uncased\", \"multi-qa-mpnet-base-dot-v1\", \"all-mpnet-base-v2\"]\n",
    "models = [\"bert-base-uncased\", \"multi-qa-mpnet-base-dot-v1\", \"all-mpnet-base-v2\"]\n",
    "\n",
    "model_name_map = {\n",
    "    \"distiluse-base-multilingual-cased-v2\": \"multi_distiluse\", \n",
    "    \"paraphrase-multilingual-mpnet-base-v2\": \"multi_mpnet\", \n",
    "    \"bert-base-uncased\": \"bert_uncased\", \n",
    "    \"multi-qa-mpnet-base-dot-v1\": \"multiqa_mpnet_dot\", \n",
    "    \"all-mpnet-base-v2\": \"mpnet\"\n",
    "}\n",
    "\n",
    "for jurisdiction in tqdm(df[\"jurisdiction\"].unique()):\n",
    "    for model_name in models:\n",
    "        aux = df.copy(True)\n",
    "        aux[\"summaryEn\"] = aux[\"summaryEn\"].apply(summary_preprocessing_transformer)\n",
    "        if \"bert\" not in model_name:\n",
    "            model = SentenceTransformer(\"../models/\" + model_name).to(device)\n",
    "            emb_vec = np.asarray(aux[aux[\"jurisdiction\"] == jurisdiction][\"summaryEn\"].apply(model.encode).tolist())\n",
    "        else:\n",
    "            model = BertModel.from_pretrained(\"../models/\" + model_name).to(device)\n",
    "            tokenizer = BertTokenizer.from_pretrained(\"../models/\" + model_name)\n",
    "\n",
    "            emb_vec = np.asarray(aux[aux[\"jurisdiction\"] == jurisdiction][\"summaryEn\"].apply(encode_sentence_bert, args = (model, tokenizer,)).tolist())\n",
    "\n",
    "        os.mkdir(f\"../data/caselaw_emb/{jurisdiction}\") if jurisdiction not in os.listdir(\"../data/caselaw_emb/\") else 1\n",
    "        aux_df = df[df[\"jurisdiction\"] == jurisdiction].copy(True)\n",
    "        aux_df[f\"embedding_{model_name}\"] = list(emb_vec)\n",
    "        aux_df.to_pickle(f\"../data/caselaw_emb/{jurisdiction}/emb_{model_name_map[model_name]}.pickle\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facilex_caselaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
