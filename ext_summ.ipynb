{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import evaluate\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "gpu_id = 2\n",
    "device = f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "multi_lexsum = load_dataset(\"allenai/multi_lexsum\", name=\"v20220616\")\n",
    "modified_dataset = multi_lexsum[\"test\"].filter(lambda x: x[\"summary/short\"] != None)\n",
    "# modified_dataset = modified_dataset.map(lambda x: {\"sources\": [a.encode('utf-8').decode('utf-8').strip().split(' ') for a in x[\"sources\"]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_into_paras(sources):\n",
    "    all_docs = []\n",
    "    for source in sources:\n",
    "        sents = []\n",
    "        for doc in source:\n",
    "            text = re.split(\"\\n\", doc)\n",
    "            text = [sentence for sentence in text if sentence != \"\"]\n",
    "            sents.append(text)\n",
    "        all_docs.extend(sents)\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexrank import STOPWORDS, LexRank\n",
    "import os\n",
    "import dill\n",
    "\n",
    "if \"lexrank.pickle\" not in os.listdir():\n",
    "    training_docs = split_into_paras(modified_dataset[\"sources\"][:100])\n",
    "    lex_rank = LexRank(training_docs, stopwords = STOPWORDS[\"en\"], show_progress = True)\n",
    "    dill.dump(lex_rank, open(\"lexrank.pickle\", \"wb\"))\n",
    "else:\n",
    "    lex_rank = dill.load(open(\"lexrank.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = \"test \\x9b\"\n",
    "# print(t.encode(\"utf-8\").decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are a legal expert, knowledgeable in all legal cases, their structure, and what they contain. You are tasked with creating one summary from multiple legal texts. Your summary must contain around 130 words.\n",
      "<</SYS>>\n",
      "\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# law_prompt = f'''\\nYou are given a number of summaries from legal documents. Create one summary that encompasses all of them:\\n'''\n",
    "# law_prompt = f'''Task: Create one summary from the following chunks of legal text. It must be aroung 130 words long.\\n'''\n",
    "law_prompt = f'''You are a legal expert, knowledgeable in all legal cases, their structure, and what they contain. You are tasked with creating one summary from multiple legal texts. Your summary must contain around 130 words.'''\n",
    "\n",
    "# our_system_prompt = \"\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\" # Please do NOT change this\n",
    "our_system_prompt = \"\"\n",
    "# system_prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}{law_prompt}<</SYS>>\\n\\n [/INST]\"\n",
    "system_prompt = f\"\"\"<s>[INST] <<SYS>>{our_system_prompt}\n",
    "{law_prompt}\n",
    "<</SYS>>\n",
    "\"\"\"\n",
    "system_prompt_size = len(tokenizer.encode(system_prompt))\n",
    "print(system_prompt)\n",
    "print(system_prompt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c507429fb59342e2aceab2c692c95437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:830: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"../models/law-chat\", local_files_only = True, device_map=device, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/law-chat\", local_files_only = True, use_fast=False, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # NOTE:\n",
    "# # # If you want to apply your own system prompt, please integrate it into the instruction part following our system prompt like this:\n",
    "# # your_system_prompt = \"Please, answer this question faithfully.\"\n",
    "\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "# outputs = model.generate(input_ids=inputs, max_new_tokens = 4096)[0]\n",
    "\n",
    "# answer_start = int(inputs.shape[-1])\n",
    "# pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n",
    "\n",
    "# print(f'### User Input:\\n{user_input}\\n\\n### Assistant Output:\\n{pred}')\n",
    "# print(len(pred.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "<s> <<SYS>> [INST] {system prompt} <</SYS>> {user_input} [/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are a legal expert, knowledgeable in all legal cases, their structure, and what they contain. You are tasked with creating one summary from multiple legal texts. Your summary must contain around 130 words.\n",
      "<</SYS>>\n",
      "\n",
      "\n",
      "Task: Summarize the following legal texsts into one summary. Include as much relevant information as possible, and carefully think about the texts:\n",
      "\n",
      "118. The aforesaid pattern or practice of age discrimination by Best Buy was willful. 119. The Plaintiffs are each 40 years of age or older, and are within the class of persons protected against age discrimination by the ADEA, 29 U.S.c. § 621, et seq., and the MHRA, Minn. Stat. § 363A.02, et seq. 120. The Plaintiffs are among the former employees of Best Buy who have been adversely affected by the aforesaid pattern or practice of age discrimination. Verne A. Hall 121. Hall was employed with Best Buy as a Software Engineer. 122. Hall was well qualified for his Software Engineer position and performed his duties in a proper, satisfactory and competent manner. 123. Best Buy terminated Hall's employment on or about October 14, 2003, when Hall, who was born on July 23, 1943, was 60 years old.\n",
      "304. As a direct and proximate result ofthe aforesaid unlawful and willful pattern or practice of age discrimination by Best Buy in violation of the ADEA, each ofthe Plaintiffs has suffered damages in an amount to be determined at trial, including, but not limited to, lost salary, bonuses, and other forms of compensation and lost retirement benefits, insurance benefits, and other employee benefits.\n",
      "302. The above-named Plaintiffs and others similarly situated were adversely affected by the aforesaid pattern or practice of unlawful, willful age discrimination by Best Buy.\n",
      "Best Buy Company, Inc. and Best Buy\n",
      "310. Best Buy discriminated against Aschenbeck because of her age in willful violation ofthe ADEA and MHRA by engaging in the aforesaid pattern or practice of age discrimination and by terminating Aschenbeck's employment in 2004.\n",
      "\n",
      "Best Buy who have been\n",
      "employees at Best Buy.\n",
      "Buy Co., Inc.\n",
      "101. As part of its pattern or practice of age discrimination, Best Buy discriminated\n",
      "102. As part of its pattern or practice of age discrimination, Best Buy discriminated\n",
      "\n",
      "unlawful, willful age discrimination by Best Buy.\n",
      "Best Buy.\n",
      "Best Buy in the is department and other\n",
      "Best Buy as follows:\n",
      "Buy to Plaintiffs and other similarly situated employees of\n",
      "\n",
      "that this Court dismiss Count Three of plaintiffs’ Amended Complaint because plaintiffs lack\n",
      "lack standing because none of the named plaintiffs signed waivers releasing Best Buy from\n",
      "\f\n",
      "Word 20119608.1\n",
      ")\n",
      "\n",
      "Buy Co., Inc.\n",
      "employees at Best Buy.\n",
      "125. The Plaintiffs are among the former employees of Best Buy who have been\n",
      "102. As part of its pattern or practice of age discrimination, Best Buy discriminated\n",
      "103. As part of its pattern or practice of age discrimination, Best Buy discriminated\n",
      "\n",
      "unlawful, willful age discrimination by Best Buy.\n",
      "Best Buy also discriminated on the basis of age, in willful violation of\n",
      "Best Buy as follows:\n",
      "Best Buy in the is\n",
      "Best Buy in the is department and other\n",
      "\n",
      "Protection Act (“OWBPA”) (Count III of Plaintiffs’ Amended Complaint (Docket Nos. 10 and\n",
      "\f\n",
      ")\n",
      "UNITED STATES DISTRICT COURT DISTRICT OF MINNESOTA\n",
      "Verne A. Hall, et al., Plaintiffs,\n",
      "\n",
      "These two cases are related. In the interest of judicial economy, the Court HEREBY ORDERS that the case captioned Loeb v. Best Buy, No. 05-720 (MJD/AJB) be closed, and that Loeb become part of the main case, Hall et al. v. Best Buy, No. 04-4812 (MJD/AJB). The Pretrial Scheduling Order issued in Hall and the amendments thereto shall now apply to Loeb also.\n",
      "\f\n",
      "2\n",
      "UNITED STATES DISTRICT COURT DISTRICT OF MINNESOTA\n",
      "VERNE A. HALL, et al., Plaintiffs,\n",
      "\n",
      "\f\n",
      "s/Michael J. Davis Michael J. Davis United States District Court Judge\n",
      "UNITED STATES DISTRICT COURT DISTRICT OF MINNESOTA\n",
      ")\n",
      "Verne A. Hall, et al.,\n",
      "\n",
      "\f\n",
      "1\n",
      "ORDER MICHAEL J. DAVIS, District Court. *1 IT IS HEREBY ORDERED that Defendants’ Motion to Strike Revised Expert Statistical Report of Joseph B. Kadane [Doc. No. 311] is DENIED.\n",
      "Named Expert: Joseph B. Kadane Attorneys and Law Firms Craig A. Brandt, Jennifer J. Olson, Julie L. Boehmke, Laurie A. Knocke, Stephen J. Snyder, and Ugo A. Ukabam, Gray Plant Mooty Mooty & Bennett, PA Counsel for Plaintiffs. Jay B. Streitz, Siegel Brill Greupner Duffy & Foster, PA, Counsel for Opt-in Plaintiffs. David L. Shulman, Law Office of David L. Shulman PLLC, Counsel for Plaintiff Jeffrey Loeb. Charles O. Lentz, Janet C. Evans, Kari Thoe Crone, Kelly K. Pierce, Lisa L. Heller, Sara Anspach Poulos, Stacey P. Slaughter, and Joel A. Mintzer, Robins Kaplan Miller & Ciresi LLP, Counsel for Defendants. Opinion\n",
      "BEST BUY COMPANY, INC. and Best Buy Enterprise Services, Inc., Defendants. Civil File No. 04-4812 (MJD/AJB). | Aug. 3, 2006.\n",
      "\n",
      "Counsel: [*1] For Verne A Hall, Erik M Jothen, Susan J Aschenbeck, Donald P Brennan, Roberta S (Filler) Carlson, John J Carney, Fang-Pai Chen, Ronnie B Clausen, David L Draper, Gary L Flemino, Debra Jean Foster, Linda K Giles, Janice B Hanson, Richard W Hartmann, Paul O Holtan, Audre M Hudson, Oleg Ivanov, Vaughn Edwen James, Hugh F Juergens, Glen A Juntti, Sharon L Kelly, Vladimir Kessler, Sally M Kleiner, Randall S Knox, LeRae L Lemon, Shawn Xiao Liu, Esther G Mazurek, Daniel J McKenzie, Thomas M Noska, Roy D Okins, Richard David Olund, Personal representative for the estate of Richard David Olund, Gregory J Pettis, Joy G Piao, Boris L Rabichev, Joy M Reinhart, JoAnn Baird Shoemaker, Kent D Smith, Lynette M Steuck, Gregory K Stoner, Billy S Summers, Marina Vorobeychik, Richard L Walstrom, Philip B Winters, Ernest R Zahradka, for and on behalf of themselves and other persons similarly situated, Plaintiff: Craig A Brandt, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; Jennifer J Olson, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; Julie L Boehmke, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; Laurie A Knocke, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; [*2] Stephen J Snyder, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; Ugo A Ukabam, Gray Plant Mooty Mooty & Bennett, PA, Mpls, MN.\n",
      "\fOpinion by: Michael J. Davis\n",
      "Prior History: Hall v. Best Buy Co., 2006 U.S. Dist. LEXIS 40235 (D. Minn., June 15, 2006)\n",
      "For Thomas Aubrecht, Plaintiff: Jennifer J Olson, Gray Plant Mooty Mooty & Bennett, PA, Minneapolis, MN; Wood R Foster, Jr., Siegel Brill Greupner Duffy & Foster, PA, Mpls, MN.\n",
      "2. Plaintiffs may file a single memorandum of law in response to Defendants' six motions for partial summary judgment on individual age discrimination claims, which shall not exceed 75,000 words.\n",
      "\n",
      "3 AFFIDAVIT of Service by Verne A Hall re 1 Complaint,,,,, Summons Issued Plaintiffs' Affidavit of Service on Best Buy Enterprise Services, Inc. (Snyder, Stephen) (Entered: 11/22/2004)\n",
      "449 AFFIDAVIT of Laurie A. Knocke in OPPOSITION TO 436 MOTION for Order to Set a Scheduling Conference including Exhibit A filed by Verne A Hall. (Snyder, Stephen) (Entered: 08/31/2006)\n",
      "158 AFFIDAVIT of Laurie A. Knocke in SUPPORT OF 155 MOTION to Compel Discovery of Electronic Documents in Native Format filed by Verne A Hall. (Brandt, Craig) (Entered: 01/25/2006)\n",
      "445 AFFIDAVIT of Craig A. Brandt in OPPOSITION TO 431 MOTION for Order to File Reply Brief Regarding the Expert Testimony of Dr. Joseph Kadane filed by Verne A Hall. (Attachments: # 1 Exhibit(s) Exhibit Index, Exhibits A and B)(Snyder, Stephen) (Entered: 08/30/2006)\n",
      "76 EXHIBIT re 75 Affidavit in Support of Motion (placeholder − Ex. A filed under seal) by Verne A Hall filed by Verne A Hall. (Knocke, Laurie) (Entered: 08/11/2005)\n",
      "\n",
      "These two cases are related. In the interest of judicial economy, the Court HEREBY ORDERS that the case captioned Loeb v. Best Buy, No. 05-720 (MJD/AJB) be closed, and that Loeb become part of the main case, Hall et al. v. Best Buy, No. 04-4812 (MJD/AJB). The Pretrial Scheduling Order issued in Hall and the amendments thereto shall now apply to Loeb also.\n",
      "Opinion by: Michael J. Davis\n",
      "Subsequent History: Motion granted by Hall v. Best Buy Co., 2006 U.S. Dist. LEXIS 56515 (D. Minn., Aug. 11, 2006) Summary judgment granted by Loeb v. Best Buy Co., 2007 U.S. Dist. LEXIS 58039 (D. Minn., Aug. 6, 2007)\n",
      "Reporter: 2006 U.S. Dist. LEXIS 40235 VERNE A. HALL, et al., Plaintiffs v. BEST BUY COMPANY, INC. and BEST BUY ENTERPRISE SERVICES, INC., Defendants; JEFFERY LOEB, Plaintiff v. BEST BUY COMPANY, INC. and BEST BUY ENTERPRISE SERVICES, INC., Defendants\n",
      "Hall v. Best Buy Co.\n",
      "\n",
      "{ANSWER} [/INST]\n"
     ]
    }
   ],
   "source": [
    "def prompt_from_sources(sources):\n",
    "    # truncate each chunk so max output is < 4096\n",
    "    # use embeddings from dense models instead of idf\n",
    "    # segment with high granularity - each sentence within the paragraph\n",
    "    token_size = 0\n",
    "    prompt = \"\"\n",
    "    summary_too_long = False\n",
    "    summary_size = 5\n",
    "    while not summary_too_long:\n",
    "        summ = []\n",
    "        for test_doc in split_into_paras([sources]):\n",
    "            summary = lex_rank.get_summary(test_doc, threshold = 0.3, summary_size=summary_size)\n",
    "            token_size += len(tokenizer.encode(summary))\n",
    "            if token_size + 250 + system_prompt_size > 4096: # too much information, the model would not be able to generate the output\n",
    "                summary_too_long = True\n",
    "                break\n",
    "            summ.append(summary)\n",
    "\n",
    "        if summary_too_long:\n",
    "            summary_size -= 1\n",
    "            print(\"Too long\")\n",
    "            if summary_size < 1:\n",
    "                break \n",
    "            summary_too_long = False\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    user_input = \"\\n\\nTask: Summarize the following legal texsts into one summary. Include as much relevant information as possible, and carefully think about the texts:\\n\\n\" + \"\\n\\n\".join([\"\\n\".join(summary) for summary in summ]) + \"\\n\\n{ANSWER} [/INST]\"\n",
    "    prompt = system_prompt + user_input\n",
    "\n",
    "    # print(len(tokenizer.encode(prompt)))\n",
    "    # print(prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "print(prompt_from_sources(modified_dataset[\"sources\"][100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:21<00:21, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:24<00:00, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "predicted_summaries = []\n",
    "slice_idx = slice(100,102)\n",
    "for sources in tqdm(modified_dataset[\"sources\"][slice_idx]):\n",
    "    prompt = prompt_from_sources(sources)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True, truncation=True, max_length=4095).input_ids.to(model.device)\n",
    "    outputs = model.generate(input_ids=inputs, max_new_tokens = np.min([250, 4096 - len(inputs[0])]))[0] # \n",
    "\n",
    "    answer_start = int(inputs.shape[-1])\n",
    "    pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n",
    "\n",
    "    # print(f'### User Input:\\n{user_input}\\n\\n### Assistant Output:\\n{pred}')\n",
    "    print(len(pred.split(\" \")))\n",
    "\n",
    "    predicted_summaries.append(pred)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118. The aforesaid pattern or practice of age discrimination by Best Buy was willful. 119. The Plaintiffs are each 40 years of age or older, and are within the class of persons protected against age discrimination by the ADEA, 29 U.S.c. § 621, et seq., and the MHRA, Minn. Stat. § 363A.02, et seq. 120. The Plaintiffs are among the former employees of Best Buy who have been adversely affected by the aforesaid pattern or practice of age discrimination. Verne A Hall 121. Hall was employed with Best Buy as a Software Engineer. 122. Hall was well qualified for his Software Engineer position and performed his duties in a proper, satisfactory and competent manner. 123. Best Buy terminated Hall's employment on or about October 14, 2003, when Hall, who was born on July 23, 1943, was 60 years old.\n"
     ]
    }
   ],
   "source": [
    "print(predicted_summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrouge_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredicted_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodified_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary/short\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslice_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py:450\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py:509\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m batch \u001b[38;5;241m=\u001b[39m {input_name: batch[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_feature_from_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_writer()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py:590\u001b[0m, in \u001b[0;36mEvaluationModule._infer_feature_from_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, v[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_example(example)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/evaluate/module.py:590\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_example(example)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(rouge_score.compute(predictions = predicted_summaries, references = modified_dataset[\"summary/short\"][slice_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
